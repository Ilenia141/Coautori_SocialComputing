{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1° Progetto Social Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the needed libraries, read the .csv file and set the SERP API key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import pyvis as pv\n",
    "import json\n",
    "import numpy as np\n",
    "from serpapi import GoogleScholarSearch\n",
    "\n",
    "GoogleScholarSearch.SERP_API_KEY = 'ca2e08520035a8eb9bd084ee45f9fe6eb2dd733c6eab0bb596e2f9546fe0d6eb' #Denis SERP KEY\n",
    "df = pd.read_csv(\"data\\\\nodes.csv\")  #read nodes.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to calculate the queries looking for the requested people, for each row in the dataframe.\n",
    "We will save the queries into 'result' and the affiliations into 'aff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = []\n",
    "result = []\n",
    "aff = [] #save the affiliations from nodes.csv\n",
    "name_authors = []\n",
    "name_coauthors_per_author = [] #will be used later, for now we store the authors names\n",
    "for index, row in df.iterrows():\n",
    "    params = {\"engine\": \"google_scholar_profiles\", \"hl\": 'en', \"mauthors\": row['name']}\n",
    "    search.append(GoogleScholarSearch(params))  #obtain the queries of all the authors\n",
    "    result.append(search[index].get_dict()) #transform the json into a dictionary for each query\n",
    "    aff.append(row['affiliations'])\n",
    "    name_authors.append(row['name'])\n",
    "    name_coauthors_per_author.append([row['name']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to find, for every .json file we stored into 'results' (1°for loop), for each profile inside the analyzed json (2°for loop), the profile we were looking for (using the affiliation) and store all the information regarding the author_id, cited_by and the interests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author = []\n",
    "cited = []\n",
    "interests = []\n",
    "for index_result, value_result in enumerate(result): #for each json I retrieve the data I need\n",
    "    for value_profiles in result[index_result]['profiles']: #for each profile inside of a single json\n",
    "        interests_per_person = [] #list of interests for every person; clean the list at every iteration\n",
    "        if (value_profiles['affiliations']) == aff[index_result]: #if it's the profile im looking for, \n",
    "                                                                  #then save save author_id, cited_by & interests\n",
    "            author.append(value_profiles['author_id'])\n",
    "            cited.append(value_profiles['cited_by'])\n",
    "\n",
    "            for i in value_profiles['interests']: #interests can be multiple for every person, so let's group them by person\n",
    "                interests_per_person.append(i['title'])\n",
    "            \n",
    "            interests.append(interests_per_person)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's update the nodes.csv file with new columns with data retrieved from the queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['author_id'] = author\n",
    "df['cited_by'] = cited\n",
    "df['interests'] = interests\n",
    "df.to_csv(\"data\\\\nodes.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's retrieve the list of the coauthors for each person in nodes.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = []\n",
    "result = []\n",
    "coauthors = []\n",
    "for index, value in enumerate(author):\n",
    "    params = {\"engine\": \"google_scholar_author\", \"hl\": 'en', \"author_id\": value} #searching with the author_id\n",
    "    search.append(GoogleScholarSearch(params))\n",
    "    result.append(search[index].get_dict())\n",
    "    coauthors.append(result[index]['co_authors']) #list of coauthors for every author"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the 7 authors, we get into their profiles (via id) and download coauthors names, grouped by author "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index_author, value_author in enumerate(coauthors): #for each author\n",
    "    coauthors_names = []\n",
    "    for index_coauthor, value_coauthor in enumerate(coauthors[index_author]): #for each coauthor of the selected author\n",
    "        coauthors_names.append(value_coauthor['name']) #save the name of the coauthor\n",
    "\n",
    "    name_coauthors_per_author[index_author] = coauthors_names #list of coauthor grouped by authors\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the names of the coauthors to look for researchers matching that name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = []\n",
    "result = []\n",
    "for index, value in enumerate(name_coauthors_per_author): #for each coauthor list of an author\n",
    "    for i, v in enumerate(value): #for each coauthor of a coauthor list\n",
    "        params = {\"engine\": \"google_scholar_profiles\", \"hl\": 'en', \"mauthors\": v}\n",
    "        search.append(GoogleScholarSearch(params))\n",
    "        result.append(search[i].get_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the list of all the coauthors, we select for each coauthor the first result (with index 0) and take all the information requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author = []\n",
    "name = []\n",
    "affiliations = []\n",
    "cited = []\n",
    "interests = []\n",
    "for index_result, value_result in enumerate(result): #for each json I retrieve the data I need\n",
    "        interests_per_person = [] #list of interests for every person; clean the list at every iteration\n",
    "        \n",
    "        author.append(value_result['profiles'][0]['author_id']) #take the first profile appearing on the query result\n",
    "        name.append(value_result['profiles'][0]['name'])\n",
    "        affiliations.append(value_result['profiles'][0]['affiliations'])\n",
    "        cited.append(value_result['profiles'][0]['cited_by'])\n",
    "\n",
    "        if('interests' in value_result['profiles'][0]): #check if the coauthor actually has any interests\n",
    "            for i in value_result['profiles'][0]['interests']: #for every interests, put the name into a list\n",
    "                interests_per_person.append(i['title'])\n",
    "        \n",
    "        interests.append(interests_per_person) #list ehere each item is a list of interests of the specific coauthor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dataframe of coauthors through a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'name': name,\n",
    "    'affiliations': affiliations,\n",
    "    'author_id': author,\n",
    "    'cited_by': cited,\n",
    "    'interests': interests\n",
    "}\n",
    "\n",
    "df2 = pd.DataFrame(data)\n",
    "df2 = df2.drop_duplicates(subset='author_id') #delete the duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We concatenate authors and coauthors in the same dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"data\\\\nodes.csv\")\n",
    "df = pd.concat([df1, df2])\n",
    "df = df.drop_duplicates(subset='author_id')\n",
    "df.to_csv(\"data\\\\nodes.csv\", index = False) #overwrite nodes.csv with authors and coauthors combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a new dataframe representing the edges between author-coauthor, both ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author1 = [] #1st column dataframe\n",
    "author2 = [] #2nd column dataframe\n",
    "\n",
    "for index_author, value in enumerate(name_coauthors_per_author): #for every author, analyze the coauthor list\n",
    "    for coauthor in value: #for every coauthor in the coauthor list\n",
    "        author1.append(name_authors[index_author])\n",
    "        author2.append(coauthor)\n",
    "\n",
    "data = {\n",
    "    'author1': author1,\n",
    "    'author2': author2\n",
    "}\n",
    "df3 = pd.DataFrame(data) #create a new dataframe for the edges\n",
    "df3.to_csv(\"data\\\\edges.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Progetto1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
